What is machine learning
* its a methof of data analysis that automates analytical model building 
* can be used from a ariety of tasks but we focus on text sentiment analysis 

Two types of ML learning
1) Supervised
* algorithms that are trained using labeled examples, i.e. an input where the desired output is known 
* we first fit/train the model on a trainig data and then test the model on testing data

Machine Learning Process 
1) data aquisition
2) data cleaning - text data will use vectorization, remove missing data
3) split the data to (y-lable is often something you create, and the features are from your dataset; before we fit the model, we split the data to test and training set))
3.1) training data --> model traiing and building, fitting the model in the training data (70% of the data)
3.2) test data 
4) Model testing --> evluate the model (at this stage you can go back to the model training and building to adjust anything that is needed)
5) model deployment

How do we Evaluation? 
* we do this through classification metrics
* Kay classification metrics to know include
** accuracy
    *** number of correct predictions made by the model divided by the total number of predictions 
    *** accuracy is good for balanced classes but its NOT good for unbalanced classes (think of classes as the data points, if they are all the same and uniform, it will do poorly - this when you want to look into recall and precision)
** recall
    *** ability of the model to find all the relvant cases within a dataset or in other words, is the number of true positives divided by the number of true positives plust the number of false negatives
** precision
    *** ability of the classification model to identify only the relevant data points. or in other words, the true positives divided by the number of true positives plus the number of false positives 
** F1-score (combination of recall and precision)
    *** harmonic mean of precision and recall taking both metrics 
    *** the reason that it uses harmonic mean instead of simple average because it punishes extreme values 

* regardless of how many classes you have, the model can only have two output, either its right or its wrong in its prediction;
  however, in the real world not all incorrect or correct matches hold equal value, therefore we need to do more work and take other factors into account.
* often if we are dealing with raw text we would need to do some vectorization. 
* we could organize the prected value compared to the real value in a confusion metrix

* Confusion metrix (refer to the confusion_matrix.png)

Note: Text classification and recognition is a very commonly used in ML

-----------
ML process in more details
1) Problem Definition: Clearly define the problem you're trying to solve.

2) Data Collection: Gather the data needed for your ML problem.

3) Data Preprocessing: Clean and preprocess the data. This step might involve handling missing values, normalizing or standardizing data, encoding categorical variables, etc.

4) Feature Engineering: Select and possibly transform the most relevant features for your model.

5) Model Selection: Choose an appropriate algorithm or algorithms for your ML problem.

6) Model Training: Train your model using the training dataset.

7) Model Evaluation:

* Cross-Validation: Before final evaluation, you often use techniques like k-fold cross-validation during training to validate your model on different subsets of the data. This helps ensure that the model generalizes well and is not just memorizing the training data (overfitting).
* Evaluation on a Test Set: After training, evaluate your model's performance on a separate test dataset that was not used during the training process. This is crucial to gauge how well your model will perform on new, unseen data.
* Metrics: Use appropriate evaluation metrics (like accuracy, precision, recall, F1-score, ROC-AUC for classification problems; MSE, RMSE, MAE for regression problems) to quantify model performance.
* Model Tuning: Based on the evaluation, you might go back to tune your model, adjust parameters, or even try different algorithms.

8)Model Refinement:
* Based on the evaluation, you might adjust model parameters (hyperparameter tuning), or revisit earlier steps like feature engineering to improve performance.

9) Model Deployment: Once you have a model that performs satisfactorily, you can deploy it to a production environment where it will start making predictions on real-world data.

10) Monitoring and Maintenance: Continuously monitor the model's performance in the production environment and retrain or update it as necessary to maintain its accuracy over time.